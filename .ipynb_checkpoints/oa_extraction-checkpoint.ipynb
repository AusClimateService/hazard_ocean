{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4079b8ea-e9c4-4291-a0d4-7dc10d6fac03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "from dask_jobqueue import PBSCluster\n",
    "from dask.distributed import Client\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import flox\n",
    "import flox.xarray\n",
    "import pandas as pd\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.dates import DateFormatter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7741934-725b-4ed6-bb5f-e0626e17cc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-04 09:11:11,836 - distributed.preloading - INFO - Creating preload: /g/data/hh5/public/apps/dask-optimiser/schedplugin.py\n",
      "2024-06-04 09:11:11,841 - distributed.utils - INFO - Reload module schedplugin from .py file\n",
      "2024-06-04 09:11:11,849 - distributed.preloading - INFO - Import preload module: /g/data/hh5/public/apps/dask-optimiser/schedplugin.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modifying workers\n"
     ]
    }
   ],
   "source": [
    "client = Client(threads_per_worker=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db05f2df-2202-478a-bb16-6e1172b20894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate monthly climatology and convert to single precision\n",
    "def monthly_climatology(ds, time_dim):\n",
    "    \"\"\"\n",
    "    Calculate the monthly climatology for a given dataset.\n",
    "\n",
    "    This function takes an xarray dataset and computes the monthly climatology\n",
    "    by averaging data for each month over all years. The function adds a 'month'\n",
    "    dimension to the dataset based on the provided time dimension.\n",
    "\n",
    "    Parameters:\n",
    "        ds (xarray.Dataset): The input dataset containing the time dimension.\n",
    "        time_dim (str): The name of the time dimension in the dataset.\n",
    "\n",
    "    Returns\n",
    "        xarray.Dataset: Dataset with the mean values for each month across all years. \n",
    "        The data type of returned values is float32.\n",
    "    \"\"\"\n",
    "    ds['month'] = ds[time_dim].dt.month\n",
    "    climatology_cohorts = flox.xarray.xarray_reduce(\n",
    "        ds,\n",
    "        'month',\n",
    "        func='mean',\n",
    "        method='cohorts',\n",
    "    )\n",
    "    return climatology_cohorts.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27a33cfe-ced6-4d7a-bbe3-8289bf8aeb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory paths\n",
    "dir1 = '/scratch/xv83/rxm599/historical/'\n",
    "dir2 = '/scratch/xv83/rxm599/future/'\n",
    "dir0 = '/scratch/xv83/rxm599/pi/'\n",
    "\n",
    "# Load datasets with chunking\n",
    "dbgc1 = xr.open_mfdataset(dir1 + \"files*.nc\", parallel=True, chunks={'TIME41': 10})\n",
    "dbgc2 = xr.open_mfdataset(dir2 + \"files*.nc\", parallel=True, chunks={'TIME41': 10})\n",
    "dbgc0 = xr.open_mfdataset(dir0 + \"files*.nc\", parallel=True, chunks={'TIME41': 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b63a82fc-187e-4e1c-b0a5-467e6d1f60da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set GWL periods\n",
    "GWL_periods = {\n",
    "    'current': ('1995-01-01', '2014-12-31'),\n",
    "    'GW1p2': ('2001-01-01', '2020-12-31'),\n",
    "    'GW1p5': ('2015-01-01', '2034-12-31'),\n",
    "    'GW2p0': ('2030-01-01', '2049-12-31'),\n",
    "    'GW3p0': ('2053-01-01', '2072-12-31'),\n",
    "    'GW4p0': ('2074-01-01', '2093-12-31')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30870cab-2c0e-45dd-a756-b39395e553ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process and save climatology data\n",
    "def process_climatology(ds, time_dim, start, end, variable, period):\n",
    "    data = getattr(ds, variable).sel(**{time_dim: slice(start, end)}).persist() \n",
    "    clim = monthly_climatology(data, time_dim).persist()\n",
    "\n",
    "    file_path = f'/g/data/ia39/ncra/ocean/peacey/{variable}_climatology_{period}.nc'\n",
    "    \n",
    "    # Save as netCDF\n",
    "    clim.to_netcdf(file_path, compute=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5a9e225-dc44-41bb-aed0-6f5e923ae792",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "# Process current period\n",
    "process_climatology(dbgc1, 'TIME41', *GWL_periods['current'], 'OAR', 'current')\n",
    "process_climatology(dbgc1, 'TIME41', *GWL_periods['current'], 'PH', 'current')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07b99495-2afb-48ac-8c53-3c8fc1547aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# Process PI\n",
    "process_climatology(dbgc0, 'TIME41', *GWL_periods['current'], 'OAR', 'PI')\n",
    "process_climatology(dbgc0, 'TIME41', *GWL_periods['current'], 'PH', 'PI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19d68662-0b5d-4914-980b-f4e339072661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 36s, sys: 39.4 s, total: 3min 16s\n",
      "Wall time: 7min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# Process future\n",
    "for period, (start, end) in GWL_periods.items():\n",
    "    if period == 'current':\n",
    "        continue\n",
    "    process_climatology(dbgc2, 'TIME41', start, end, 'OAR', period)\n",
    "    process_climatology(dbgc2, 'TIME41', start, end, 'PH', period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "903cad75-4172-4adf-bed5-4c134b7728f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory paths for SST\n",
    "dir1_new = '/g/data/fp2/OFAM3/jra55_historical.1/surface/'\n",
    "dir2_new = '/g/data/fp2/OFAM3/jra55_rcp8p5/surface/'\n",
    "\n",
    "# Load datasets with chunking\n",
    "dsst1 = xr.open_mfdataset(dir1_new + 'ocean_temp_sfc_*', parallel=True, chunks={'Time': 10})\n",
    "dsst2 = xr.open_mfdataset(dir2_new + 'ocean_temp_sfc*.nc', parallel=True, chunks={'Time': 10})\n",
    "\n",
    "# Process SST\n",
    "for period, (start, end) in GWL_periods.items():\n",
    "    if period == 'current':\n",
    "        process_climatology(dsst1, 'Time', start, end, 'temp', period)\n",
    "    else:\n",
    "        process_climatology(dsst2, 'Time', start, end, 'temp', period)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
